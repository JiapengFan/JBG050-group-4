{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleNaNTrans(transactions_df,  products_df):\n",
    "    for i in transactions_df[transactions_df['day'].isnull()].index:\n",
    "        transactions_df['day'][i] = transactions_df['day'][i-1]\n",
    "    \n",
    "    for i in transactions_df[transactions_df['time'].isnull()].index:\n",
    "        transactions_df['time'][i] = transactions_df['time'][i-1]\n",
    "    \n",
    "    for i in transactions_df[transactions_df['product_id'].isnull()].index:\n",
    "        for a in range(len(products_df)):\n",
    "            if transactions_df['description'][i] == products_df['description'][a]:\n",
    "                transactions_df['product_id'][i] = products_df['product_id'][a]\n",
    "                \n",
    "    for i in transactions_df[transactions_df['description'].isnull()].index:\n",
    "        for a in range(len(products_df)):\n",
    "            if transactions_df['product_id'][i] == products_df['product_id'][a]:\n",
    "                transactions_df['description'][i] = products_df['description'][a]\n",
    "\n",
    "    return transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "data_inventory = pd.read_csv(\"./data/inventory.csv\")\n",
    "data_products = pd.read_csv(\"./data/products.csv\")\n",
    "data_promotions = pd.read_csv(\"./data/promotions.csv\")\n",
    "data_simulprom = handleNaNTrans(pd.read_csv(r\".\\transactions_months_simulprom_subst.csv\"), data_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>customer</th>\n",
       "      <th>bank acount</th>\n",
       "      <th>category</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>size</th>\n",
       "      <th>std_sales_price</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>bio</th>\n",
       "      <th>basic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65737</th>\n",
       "      <td>10/3/2018</td>\n",
       "      <td>18:59:42</td>\n",
       "      <td>3894.0</td>\n",
       "      <td>65327490.0</td>\n",
       "      <td>bread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             day      time  customer  bank acount category product_id  \\\n",
       "65737  10/3/2018  18:59:42    3894.0   65327490.0    bread        NaN   \n",
       "\n",
       "      description size  std_sales_price  purchase_price  bio  basic  \n",
       "65737         NaN  1st             0.99            0.99  0.0    0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transactions[data_transactions['product_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_holiday = pd.read_excel(r\".\\feestdagen_nl_b_2018.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_holiday(data_hol):\n",
    "    data_hol = data_hol[data_holiday['Land'] == 'NL']\n",
    "    data_hol['day'] = 0\n",
    "    data_hol['day2'] = 0\n",
    "    data_hol['day_of_year'] = 0\n",
    "    \n",
    "    for i in range(len(data_hol.index)):\n",
    "        data_hol['day'][i] = data_hol['Datum'][i].strftime('%Y-%m-%d')\n",
    "        data_hol['day'][i] = datetime.strptime(data_hol['day'][i], '%Y-%m-%d').strftime('%d-%m-%Y')\n",
    "        data_hol['day2'][i] = datetime.strptime(data_hol['day'][i], '%d-%m-%Y').strftime('%d/%m/%Y')\n",
    "        data_hol['day_of_year'][i] = data_hol['Datum'][i].timetuple().tm_yday\n",
    "        \n",
    "    return data_hol\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Windows10\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Omschrijving</th>\n",
       "      <th>Land</th>\n",
       "      <th>day</th>\n",
       "      <th>day2</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Nieuwjaarsdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>01-01-2018</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>Goede vrijdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>30-03-2018</td>\n",
       "      <td>30/03/2018</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>1e Paasdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>01-04-2018</td>\n",
       "      <td>01/04/2018</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>2e Paasdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>02-04-2018</td>\n",
       "      <td>02/04/2018</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>Koningsdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>27-04-2018</td>\n",
       "      <td>27/04/2018</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>Bevrijdingsdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>05-05-2018</td>\n",
       "      <td>05/05/2018</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>Hemelvaartsdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>10-05-2015</td>\n",
       "      <td>10/05/2015</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>1e Pinksterdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>20-05-2018</td>\n",
       "      <td>20/05/2018</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>2e Pinksterdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>21-05-2018</td>\n",
       "      <td>21/05/2018</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>1e Kerstdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>25-12-2018</td>\n",
       "      <td>25/12/2018</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>2e Kerstdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>26-12-2018</td>\n",
       "      <td>26/12/2018</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Oudejaarsdag</td>\n",
       "      <td>NL</td>\n",
       "      <td>31-12-2018</td>\n",
       "      <td>31/12/2018</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum     Omschrijving Land         day        day2  day_of_year\n",
       "0  2018-01-01    Nieuwjaarsdag   NL  01-01-2018  01/01/2018            1\n",
       "1  2018-03-30   Goede vrijdag    NL  30-03-2018  30/03/2018           89\n",
       "2  2018-04-01       1e Paasdag   NL  01-04-2018  01/04/2018           91\n",
       "3  2018-04-02       2e Paasdag   NL  02-04-2018  02/04/2018           92\n",
       "4  2018-04-27       Koningsdag   NL  27-04-2018  27/04/2018          117\n",
       "5  2018-05-05   Bevrijdingsdag   NL  05-05-2018  05/05/2018          125\n",
       "6  2015-05-10   Hemelvaartsdag   NL  10-05-2015  10/05/2015          130\n",
       "7  2018-05-20  1e Pinksterdag    NL  20-05-2018  20/05/2018          140\n",
       "8  2018-05-21   2e Pinksterdag   NL  21-05-2018  21/05/2018          141\n",
       "9  2018-12-25      1e Kerstdag   NL  25-12-2018  25/12/2018          359\n",
       "10 2018-12-26      2e Kerstdag   NL  26-12-2018  26/12/2018          360\n",
       "11 2018-12-31     Oudejaarsdag   NL  31-12-2018  31/12/2018          365"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_holiday = parse_holiday(data_holiday)\n",
    "data_holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_holidays(data_prom, data_holiday):\n",
    "    data_new = data_prom\n",
    "    data_prom['holiday'] = 0\n",
    "    #nr_days = len(data_prom['day'].unique())+2\n",
    "    \n",
    "    for day in range(1, len(data_prom['day'].unique())+1):\n",
    "        unique_days = data_prom['day'].unique()\n",
    "        date = unique_days[day-1]\n",
    "        \n",
    "        if day in data_holiday['day_of_year']:\n",
    "            idx_data = data_prom[data_new['day'] == date]\n",
    "            idx = idx_data.index\n",
    "            data_prom.loc[idx, 'holiday'] = 1\n",
    "            \n",
    "    return data_prom\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_sales(total_data, product):\n",
    "    \n",
    "    product_data = total_data[total_data['description']==product]\n",
    "    category = product_data['category'].iloc[0]\n",
    "    \n",
    "    size_nan = product_data['size'].unique()\n",
    "    size_nan = [x for x in size_nan if x == x]\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    total_days_size = len(total_data['day'].unique()) * len(size_nan)\n",
    "    rows = [x for x in range(total_days_size)]\n",
    "    new_df['idx'] = rows\n",
    "    \n",
    "    new_df['week'] = 0\n",
    "    new_df['daily_sales'] = 0\n",
    "    new_df['size'] = 0\n",
    "    new_df['purchase_price'] = 0\n",
    "    new_df['month'] = 0\n",
    "    new_df['simul_promotions'] = 0\n",
    "    new_df['substitute_promotions'] = 0\n",
    "    new_df['day'] = 0\n",
    "    new_df['holiday'] = 0\n",
    "    new_df['category'] = category\n",
    "    new_df['product'] = product\n",
    "    \n",
    "    week = 1\n",
    "    index = 0\n",
    "    day_nr = 0\n",
    "    \n",
    "    for day in total_data['day'].unique():\n",
    "        daily_sales = product_data[product_data['day'] == day]\n",
    "        data_day = total_data[total_data['day'] == day]\n",
    "        \n",
    "        size_int = 0\n",
    "        for size in size_nan:\n",
    "            relevant_sales = daily_sales[daily_sales['size'] == size]\n",
    "            indexors = relevant_sales.index\n",
    "            \n",
    "            new_df.loc[index, 'daily_sales'] = len(relevant_sales)\n",
    "            new_df.loc[index, 'size'] = size_int\n",
    "            new_df.loc[index, 'week'] = week\n",
    "            new_df.loc[index, 'day'] = day \n",
    "            new_df.loc[index, 'month'] = total_data[total_data['day'] == day]['month'].iloc[0]\n",
    "            \n",
    "            try:\n",
    "                new_df.loc[index, 'simul_promotions'] = product_data[product_data['day'] == day]['simul_promotions'].iloc[0]\n",
    "            except:\n",
    "                new_df.loc[index, 'simul_promotions'] = 0\n",
    "            \n",
    "            try: \n",
    "                new_df.loc[index, 'substitute_promotions'] = relevant_sales['substitute_in_promo'].max()\n",
    "            except:\n",
    "                new_df.loc[index, 'substitute_promotions'] = 0\n",
    "            \n",
    "            try:\n",
    "                new_df.loc[index, 'purchase_price'] = relevant_sales['purchase_price'].iloc[0]\n",
    "            except: \n",
    "                new_df.loc[index, 'purchase_price'] = product_data['purchase_price'].max()\n",
    "                \n",
    "            try:\n",
    "                new_df.loc[index, 'holiday'] = data_day['holiday'].iloc[0]\n",
    "            except:\n",
    "                new_df.loc[index, 'holiday'] = 0\n",
    "            \n",
    "            index += 1\n",
    "            size_int += 1\n",
    "        \n",
    "        day_nr += 1\n",
    "        week = (day_nr // 7) + 1\n",
    "        \n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_to_restock(data_sales, data_restock):\n",
    "    \n",
    "\n",
    "    month_list = []\n",
    "    price_list = []\n",
    "    size_list = []\n",
    "    sales_list = []\n",
    "    simulprom_list = []\n",
    "    days_inbetween_list = []\n",
    "    subst_list = []\n",
    "    holiday_list = []\n",
    "    category = data_sales['category'].iloc[0]\n",
    "    product = data_sales['product'].iloc[0]\n",
    "    \n",
    "    \n",
    "    for size in data_sales['size'].unique():\n",
    "        rel_data = data_sales[data_sales['size'] == size]\n",
    "        rel_data.reset_index()\n",
    "        day_before = 0\n",
    "        \n",
    "        for day in data_inventory['day'].unique()[1:]:\n",
    "            rel_sales = rel_data[day_before : day]\n",
    "            \n",
    "            sales = sum(rel_sales['daily_sales'])\n",
    "            month = rel_sales['month'].iloc[0]\n",
    "            price = rel_sales['purchase_price'].iloc[0]\n",
    "            simulprom = rel_sales['simul_promotions'].iloc[0]\n",
    "            subst = rel_sales['substitute_promotions'].max()\n",
    "            holiday = rel_sales['holiday'].max()\n",
    "            days_inbetween = (day - day_before)\n",
    "            \n",
    "            holiday_list.append(holiday)\n",
    "            sales_list.append(sales)\n",
    "            size_list.append(size)\n",
    "            month_list.append(month)\n",
    "            price_list.append(price)\n",
    "            simulprom_list.append(simulprom)\n",
    "            subst_list.append(subst)\n",
    "            days_inbetween_list.append(days_inbetween)\n",
    "            \n",
    "            day_before = day\n",
    "            \n",
    "    raw_data = {'month':month_list,  'size':size_list, 'price':price_list, 'sales':sales_list,\n",
    "                'simul_promotions': simulprom_list, 'days_inbetween': days_inbetween_list, 'substitute_promotions': subst_list,\n",
    "                'holiday':holiday_list}\n",
    "    new_data = pd.DataFrame(raw_data)\n",
    "    new_data['category'] = category\n",
    "    new_data['product'] = product\n",
    "    return new_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_variables(total_data, productEncoder):\n",
    "    prices = total_data['price']\n",
    "    sales = total_data['sales']\n",
    "    sizes = total_data['size']\n",
    "    months = total_data['month']\n",
    "    simulprom = total_data['simul_promotions']\n",
    "    subst_prom = total_data['substitute_promotions']\n",
    "    days_inbetween = total_data['days_inbetween']\n",
    "    holidays = total_data['holiday']\n",
    "    products = np.array(total_data['product']).reshape(-1, 1)\n",
    "    products = productEncoder.transform(products).toarray().tolist()\n",
    "    \n",
    "    zipped = zip(prices, sizes, days_inbetween, months, subst_prom, simulprom, holidays)\n",
    "    x_variables = [list(a) for a in zipped]\n",
    "    x_variables = list(map(list.__add__, x_variables, products))\n",
    "    y_variables = sales\n",
    "    \n",
    "    return x_variables, y_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(bos, X_test, y_test):\n",
    "    predictions = bos.predict(X_test)\n",
    "    rounded_predictions = [round(num) for num in predictions]\n",
    "    SE = 0 \n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        squared_error = ((rounded_predictions[i] - y_test.iloc[i])**2)\n",
    "        SE += squared_error\n",
    "        \n",
    "    MSE = SE/ len(y_test)\n",
    "    MSE = int(MSE)\n",
    "    \n",
    "    RMSE = math.sqrt(MSE)\n",
    "    \n",
    "    return RMSE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_simulprom_hol = add_holidays(data_simulprom, data_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_simulprom_hol_relevant = data_simulprom_hol[data_simulprom_hol['category'] == 'vegetable']\n",
    "vegetable_products = data_simulprom_hol_relevant['description'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boerenkool gesneden',\n",
       " 'Buitenbeentjes komkommer',\n",
       " 'Nasi bami Vegetable',\n",
       " 'Basis worteltjes fijn',\n",
       " 'Courgette',\n",
       " 'SnoepVegetable tomaat',\n",
       " 'Geschrapte worteltjes',\n",
       " 'Snijbonen',\n",
       " 'Buitenbeentjes puntpaprika',\n",
       " 'Buitenbeentjes paprika',\n",
       " 'Basis sperziebonen',\n",
       " 'Komkommer',\n",
       " 'Spruiten',\n",
       " 'Wortelen',\n",
       " 'Basis Maiskorrels',\n",
       " 'SnoepVegetable worteltjes',\n",
       " 'Basis Sperziebonen',\n",
       " 'Verse zuurkool',\n",
       " 'Basis Rode kool met appel',\n",
       " 'Biologische rode kool',\n",
       " 'Biologische pompoen',\n",
       " 'Paprika',\n",
       " 'Biologische cherry tomaten',\n",
       " 'Basis erwten zeer fijn',\n",
       " 'Biologische prei',\n",
       " 'Biologische Bloemkool',\n",
       " 'Biologische courgette',\n",
       " 'Witlof',\n",
       " 'Paprika Mix',\n",
       " 'Biologische brocolli',\n",
       " 'Biologische knoflook',\n",
       " 'Rucola',\n",
       " 'WokVegetable thais',\n",
       " 'Pompoen stukjes',\n",
       " 'Biologische kikkererwten']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegetable_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Boerenkool gesneden'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, vegetable in enumerate(vegetable_products):\n",
    "    if idx == 0:\n",
    "        data_daily_complete = daily_sales(data_simulprom_hol_relevant, vegetable)\n",
    "        restocked_data_complete = daily_to_restock(data_daily_complete, data_inventory)\n",
    "    else:\n",
    "        data_daily = daily_sales(data_simulprom_hol_relevant, vegetable)\n",
    "        restocked_data = daily_to_restock(data_daily, data_inventory)\n",
    "        restocked_data_complete = restocked_data_complete.append(restocked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Boerenkool gesneden', 'Buitenbeentjes komkommer',\n",
       "       'Nasi bami Vegetable', 'Basis worteltjes fijn', 'Courgette',\n",
       "       'SnoepVegetable tomaat', 'Geschrapte worteltjes', 'Snijbonen',\n",
       "       'Buitenbeentjes puntpaprika', 'Buitenbeentjes paprika',\n",
       "       'Basis sperziebonen', 'Komkommer', 'Spruiten', 'Wortelen',\n",
       "       'Basis Maiskorrels', 'SnoepVegetable worteltjes',\n",
       "       'Basis Sperziebonen', 'Verse zuurkool',\n",
       "       'Basis Rode kool met appel', 'Biologische rode kool',\n",
       "       'Biologische pompoen', 'Paprika', 'Biologische cherry tomaten',\n",
       "       'Basis erwten zeer fijn', 'Biologische prei',\n",
       "       'Biologische Bloemkool', 'Biologische courgette', 'Witlof',\n",
       "       'Paprika Mix', 'Biologische brocolli', 'Biologische knoflook',\n",
       "       'Rucola', 'WokVegetable thais', 'Pompoen stukjes',\n",
       "       'Biologische kikkererwten'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restocked_data_complete['product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "restocked_data_complete.dropna(subset = [\"price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(restocked_data_complete, test_size = 0.25, stratify = restocked_data_complete[['month', 'size', 'product', 'days_inbetween']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./test_train_data/train.csv')\n",
    "test_df.to_csv('./test_train_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "unique_products = restocked_data_complete['product'].unique().reshape(-1, 1)\n",
    "\n",
    "productEncoder = OneHotEncoder(dtype=int).fit(unique_products)\n",
    "productEncoder = productEncoder.fit(unique_products)\n",
    "\n",
    "X_train, y_train = forest_variables(train_df, productEncoder)\n",
    "X_test, y_test = forest_variables(test_df, productEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>month</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>sales</th>\n",
       "      <th>simul_promotions</th>\n",
       "      <th>days_inbetween</th>\n",
       "      <th>substitute_promotions</th>\n",
       "      <th>holiday</th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Boerenkool gesneden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Boerenkool gesneden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Boerenkool gesneden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Boerenkool gesneden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Boerenkool gesneden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Biologische kikkererwten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>99</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Biologische kikkererwten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Biologische kikkererwten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Biologische kikkererwten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>102</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>vegetable</td>\n",
       "      <td>Biologische kikkererwten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  month  size  price  sales  simul_promotions  days_inbetween  \\\n",
       "0         0      1     0   1.29     24                 0               3   \n",
       "1         1      1     0   1.29     43                 0               4   \n",
       "2         2      1     0   1.29     24                 0               3   \n",
       "3         3      1     0   1.29     48                 0               4   \n",
       "4         4      1     0   1.29     36                 0               3   \n",
       "...     ...    ...   ...    ...    ...               ...             ...   \n",
       "3600     98     12     0   0.92     12                 0               3   \n",
       "3601     99     12     0   0.92     17                 0               4   \n",
       "3602    100     12     0   0.92      5                 0               3   \n",
       "3603    101     12     0   0.92      3                 0               4   \n",
       "3604    102     12     0   0.92      5                 0               3   \n",
       "\n",
       "      substitute_promotions  holiday   category                   product  \n",
       "0                       0.0        1  vegetable       Boerenkool gesneden  \n",
       "1                       0.0        1  vegetable       Boerenkool gesneden  \n",
       "2                       0.0        1  vegetable       Boerenkool gesneden  \n",
       "3                       0.0        1  vegetable       Boerenkool gesneden  \n",
       "4                       0.0        0  vegetable       Boerenkool gesneden  \n",
       "...                     ...      ...        ...                       ...  \n",
       "3600                    0.0        0  vegetable  Biologische kikkererwten  \n",
       "3601                    0.0        0  vegetable  Biologische kikkererwten  \n",
       "3602                    0.0        0  vegetable  Biologische kikkererwten  \n",
       "3603                    0.0        0  vegetable  Biologische kikkererwten  \n",
       "3604                    1.0        0  vegetable  Biologische kikkererwten  \n",
       "\n",
       "[3600 rows x 11 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restocked_data_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=64, max_features='sqrt', min_samples_leaf=0.01,\n",
       "                      min_samples_split=0.01, n_estimators=64)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_max_features = math.ceil(train_df.columns.shape[0]/3)\n",
    "rfr = RandomForestRegressor(n_estimators = 64, min_samples_split = 0.01, min_samples_leaf = 0.01, max_features = 'sqrt', max_depth = 64, bootstrap = True)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.59169615047823"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 250,\n",
    " 'min_samples_split': 0.02,\n",
    " 'min_samples_leaf': 0.02,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 60,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./random_forest/best_model.joblib']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# save\n",
    "joblib.dump(rfr, \"./random_forest/best_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500], 'max_features': ['auto', 'sqrt', 4], 'max_depth': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200], 'min_samples_split': [0.02, 0.05, 0.01], 'min_samples_leaf': [0.02, 0.05, 0.01], 'bootstrap': [True]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', regression_max_features]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 200, num = 10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [0.02, 0.05, 0.01]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.02, 0.05, 0.01]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=150,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'max_depth': [20, 40, 60, 80, 100, 120,\n",
       "                                                      140, 160, 180, 200],\n",
       "                                        'max_features': ['auto', 'sqrt', 4],\n",
       "                                        'min_samples_leaf': [0.02, 0.05, 0.01],\n",
       "                                        'min_samples_split': [0.02, 0.05, 0.01],\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300, 350, 400, 450,\n",
       "                                                         500]},\n",
       "                   random_state=42, verbose=10)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "#rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 150, cv = 3, verbose=10, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 350,\n",
       " 'min_samples_split': 0.01,\n",
       " 'min_samples_leaf': 0.01,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [250, 64]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [60, 50]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [0.02]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.02]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "grid_best_param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [250, 64, 350],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [60, 50, 80],\n",
       " 'min_samples_split': [0.02, 0.01],\n",
       " 'min_samples_leaf': [0.02, 0.01],\n",
       " 'bootstrap': [True]}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    for key, value in grid_best_param.items():\n",
    "        best_param = rf_random.best_params_[key]\n",
    "        if best_param not in value:\n",
    "            value.append(rf_random.best_params_[key])\n",
    "except:\n",
    "    grid_best_param = {key: [value] for key, value in rf_random.best_params_.items()}\n",
    "\n",
    "grid_best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [60, 50, 80],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [0.02, 0.01],\n",
       "                         'min_samples_split': [0.02, 0.01],\n",
       "                         'n_estimators': [250, 64, 350]})"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_grid = GridSearchCV(estimator = rf, param_grid = grid_best_param, cv = 3, n_jobs = -1, verbose = 10)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 0.01,\n",
       " 'min_samples_split': 0.01,\n",
       " 'n_estimators': 64}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_parameters(X, y):\n",
    "    X = np.array(X)\n",
    "    \n",
    "    std_slc = StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "    \n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "    \n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    \n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_depth = [2,4,6,8,10,12,14,16]\n",
    "    \n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth)\n",
    "    \n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "    \n",
    "    print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "    print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "    print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_parameters(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_general_RMSE(total_data):\n",
    "    RMSE_list = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        train_df, test_df = train_test_split(restocked_data, test_size = 0.25, stratify = restocked_data[['size', 'month', 'days_inbetween']])\n",
    "        X_train, y_train = forest_variables(train_df)\n",
    "        X_test, y_test = forest_variables(test_df)\n",
    "        \n",
    "        bos_reg = RandomForestRegressor()\n",
    "        bos_reg.fit(X_train, y_train)\n",
    "        \n",
    "        RMSE1 = RMSE(bos_reg, X_test, y_test)\n",
    "        RMSE_list.append(RMSE1)\n",
    "        mean = sum(RMSE_list)/len(RMSE_list)\n",
    "     \n",
    "    return RMSE_list, mean\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\20193727\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5.830951894845301,\n",
       "  5.744562646538029,\n",
       "  6.557438524302,\n",
       "  5.656854249492381,\n",
       "  5.477225575051661,\n",
       "  5.744562646538029,\n",
       "  6.0,\n",
       "  4.69041575982343,\n",
       "  5.0990195135927845,\n",
       "  6.0,\n",
       "  5.196152422706632,\n",
       "  4.795831523312719,\n",
       "  6.0,\n",
       "  5.0990195135927845,\n",
       "  5.196152422706632,\n",
       "  4.898979485566356,\n",
       "  4.58257569495584,\n",
       "  5.916079783099616,\n",
       "  6.244997998398398,\n",
       "  4.358898943540674],\n",
       " 5.454485929903163)"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_general_RMSE(restocked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69     10\n",
       "129    11\n",
       "181    22\n",
       "72     12\n",
       "153    21\n",
       "34     17\n",
       "43     18\n",
       "191    12\n",
       "174    10\n",
       "102     7\n",
       "173    10\n",
       "8       8\n",
       "15     13\n",
       "157    13\n",
       "186    15\n",
       "146    14\n",
       "109    10\n",
       "110    15\n",
       "56     10\n",
       "47     35\n",
       "134    19\n",
       "99     28\n",
       "38     11\n",
       "91     15\n",
       "171    11\n",
       "113     7\n",
       "71     29\n",
       "116     9\n",
       "127     7\n",
       "4      12\n",
       "17     12\n",
       "202    18\n",
       "196    10\n",
       "64     17\n",
       "199     7\n",
       "57     13\n",
       "79     14\n",
       "27     20\n",
       "140    20\n",
       "22     13\n",
       "126    16\n",
       "148    19\n",
       "141     7\n",
       "10     13\n",
       "84     12\n",
       "94     17\n",
       "187    16\n",
       "46     24\n",
       "89     20\n",
       "156    17\n",
       "166    14\n",
       "1      14\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
